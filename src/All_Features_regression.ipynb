{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "All Features_regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ9MnCG3nAsB",
        "colab_type": "code",
        "outputId": "4acfa0a5-09a8-430c-cadf-f029d1834973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnTTQyYWubTy",
        "colab_type": "code",
        "outputId": "04559063-2e0c-481b-93f7-0b3fd19d3f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/SEERNET/EmoInt.git\n",
        "%cd EmoInt\n",
        "%cp -r /content/drive/My\\ Drive/MCA\\ Project/EmoInt/tweetokenize tweetokenize\n",
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EmoInt'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/61)\u001b[K\rremote: Counting objects:   3% (2/61)\u001b[K\rremote: Counting objects:   4% (3/61)\u001b[K\rremote: Counting objects:   6% (4/61)\u001b[K\rremote: Counting objects:   8% (5/61)\u001b[K\rremote: Counting objects:   9% (6/61)\u001b[K\rremote: Counting objects:  11% (7/61)\u001b[K\rremote: Counting objects:  13% (8/61)\u001b[K\rremote: Counting objects:  14% (9/61)\u001b[K\rremote: Counting objects:  16% (10/61)\u001b[K\rremote: Counting objects:  18% (11/61)\u001b[K\rremote: Counting objects:  19% (12/61)\u001b[K\rremote: Counting objects:  21% (13/61)\u001b[K\rremote: Counting objects:  22% (14/61)\u001b[K\rremote: Counting objects:  24% (15/61)\u001b[K\rremote: Counting objects:  26% (16/61)\u001b[K\rremote: Counting objects:  27% (17/61)\u001b[K\rremote: Counting objects:  29% (18/61)\u001b[K\rremote: Counting objects:  31% (19/61)\u001b[K\rremote: Counting objects:  32% (20/61)\u001b[K\rremote: Counting objects:  34% (21/61)\u001b[K\rremote: Counting objects:  36% (22/61)\u001b[K\rremote: Counting objects:  37% (23/61)\u001b[K\rremote: Counting objects:  39% (24/61)\u001b[K\rremote: Counting objects:  40% (25/61)\u001b[K\rremote: Counting objects:  42% (26/61)\u001b[K\rremote: Counting objects:  44% (27/61)\u001b[K\rremote: Counting objects:  45% (28/61)\u001b[K\rremote: Counting objects:  47% (29/61)\u001b[K\rremote: Counting objects:  49% (30/61)\u001b[K\rremote: Counting objects:  50% (31/61)\u001b[K\rremote: Counting objects:  52% (32/61)\u001b[K\rremote: Counting objects:  54% (33/61)\u001b[K\rremote: Counting objects:  55% (34/61)\u001b[K\rremote: Counting objects:  57% (35/61)\u001b[K\rremote: Counting objects:  59% (36/61)\u001b[K\rremote: Counting objects:  60% (37/61)\u001b[K\rremote: Counting objects:  62% (38/61)\u001b[K\rremote: Counting objects:  63% (39/61)\u001b[K\rremote: Counting objects:  65% (40/61)\u001b[K\rremote: Counting objects:  67% (41/61)\u001b[K\rremote: Counting objects:  68% (42/61)\u001b[K\rremote: Counting objects:  70% (43/61)\u001b[K\rremote: Counting objects:  72% (44/61)\u001b[K\rremote: Counting objects:  73% (45/61)\u001b[K\rremote: Counting objects:  75% (46/61)\u001b[K\rremote: Counting objects:  77% (47/61)\u001b[K\rremote: Counting objects:  78% (48/61)\u001b[K\rremote: Counting objects:  80% (49/61)\u001b[K\rremote: Counting objects:  81% (50/61)\u001b[K\rremote: Counting objects:  83% (51/61)\u001b[K\rremote: Counting objects:  85% (52/61)\u001b[K\rremote: Counting objects:  86% (53/61)\u001b[K\rremote: Counting objects:  88% (54/61)\rremote: Counting objects:  90% (55/61)\u001b[K\rremote: Counting objects:  91% (56/61)\u001b[K\rremote: Counting objects:  93% (57/61)\u001b[K\rremote: Counting objects:  95% (58/61)\u001b[K\rremote: Counting objects:  96% (59/61)\u001b[K\rremote: Counting objects:  98% (60/61)\u001b[K\rremote: Counting objects: 100% (61/61)\u001b[K\rremote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 378 (delta 28), reused 40 (delta 15), pack-reused 317\u001b[K\n",
            "Receiving objects: 100% (378/378), 89.61 MiB | 45.95 MiB/s, done.\n",
            "Resolving deltas: 100% (177/177), done.\n",
            "/content/EmoInt\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating EmoInt.egg-info\n",
            "writing EmoInt.egg-info/PKG-INFO\n",
            "writing dependency_links to EmoInt.egg-info/dependency_links.txt\n",
            "writing requirements to EmoInt.egg-info/requires.txt\n",
            "writing top-level names to EmoInt.egg-info/top_level.txt\n",
            "writing manifest file 'EmoInt.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "warning: manifest_maker: MANIFEST.in, line 1: 'recursive-include' expects <dir> <pattern1> <pattern2> ...\n",
            "\n",
            "writing manifest file 'EmoInt.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/emoint\n",
            "copying emoint/__init__.py -> build/lib/emoint\n",
            "creating build/lib/emoint/tests\n",
            "copying emoint/tests/test_ensembles.py -> build/lib/emoint/tests\n",
            "copying emoint/tests/__init__.py -> build/lib/emoint/tests\n",
            "copying emoint/tests/test_featurizers.py -> build/lib/emoint/tests\n",
            "creating build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/mpqa_effect_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/emoji_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/nrc_affect_intensity_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/sentiment140_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/nrc_emotion_wordlevel_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/agree_to_disagree_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/senti_wordnet_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/sentistrength.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/liwc_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/emoji_sentiment_ranking_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/bing_liu_sentiment_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/afinn_valence_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/emoint_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/nrc_hashtag_emotion_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/negating_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/__init__.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/nrc_hashtag_sentiment_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/nrc_expanded_emotion_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/base_featurizers.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/edinburgh_embeddings_featurizer.py -> build/lib/emoint/featurizers\n",
            "copying emoint/featurizers/utils.py -> build/lib/emoint/featurizers\n",
            "creating build/lib/emoint/ensembles\n",
            "copying emoint/ensembles/__init__.py -> build/lib/emoint/ensembles\n",
            "copying emoint/ensembles/ensemble.py -> build/lib/emoint/ensembles\n",
            "copying emoint/ensembles/blending.py -> build/lib/emoint/ensembles\n",
            "creating build/lib/emoint/utils\n",
            "copying emoint/utils/reformat.py -> build/lib/emoint/utils\n",
            "copying emoint/utils/__init__.py -> build/lib/emoint/utils\n",
            "copying emoint/utils/utils.py -> build/lib/emoint/utils\n",
            "creating build/lib/emoint/resources\n",
            "copying emoint/resources/w2v.twitter.edinburgh.100d.csv.gz -> build/lib/emoint/resources\n",
            "copying emoint/resources/AFINN-en-165.txt.gz -> build/lib/emoint/resources\n",
            "copying emoint/resources/w2v-dp-BCC-Lex.txt.gz -> build/lib/emoint/resources\n",
            "copying emoint/resources/SentiWordNet_3.0.0.txt.gz -> build/lib/emoint/resources\n",
            "copying emoint/resources/nrc_affect_intensity.txt.gz -> build/lib/emoint/resources\n",
            "copying emoint/resources/emoji2vec.txt.gz -> build/lib/emoint/resources\n",
            "copying emoint/resources/AFINN-emoticon-8.txt.gz -> build/lib/emoint/resources\n",
            "copying emoint/resources/BingLiu.txt.gz -> build/lib/emoint/resources\n",
            "copying emoint/resources/Emoji_Sentiment_Data_v1.0.csv -> build/lib/emoint/resources\n",
            "copying emoint/resources/NRC-Hashtag-Emotion-Lexicon-v0.2.txt.gz -> build/lib/emoint/resources\n",
            "copying emoint/resources/NRC-emotion-lexicon-wordlevel-v0.92.txt.gz -> build/lib/emoint/resources\n",
            "copying emoint/resources/NegatingWordList.txt.gz -> build/lib/emoint/resources\n",
            "copying emoint/resources/LIWC2007.dic -> build/lib/emoint/resources\n",
            "copying emoint/resources/SentiStrength.jar -> build/lib/emoint/resources\n",
            "copying emoint/resources/mpqa.txt.gz -> build/lib/emoint/resources\n",
            "creating build/lib/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1\n",
            "copying emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1/unigrams-pmilexicon.txt.gz -> build/lib/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1\n",
            "copying emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1/pairs-pmilexicon.txt.gz -> build/lib/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1\n",
            "copying emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1/README -> build/lib/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1\n",
            "copying emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1/sentimenthashtags.txt -> build/lib/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1\n",
            "copying emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1/bigrams-pmilexicon.txt.gz -> build/lib/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1\n",
            "creating build/lib/emoint/resources/SentiStrength\n",
            "copying emoint/resources/SentiStrength/EnglishWordList.txt -> build/lib/emoint/resources/SentiStrength\n",
            "copying emoint/resources/SentiStrength/QuestionWords.txt -> build/lib/emoint/resources/SentiStrength\n",
            "copying emoint/resources/SentiStrength/EmotionLookupTable.txt -> build/lib/emoint/resources/SentiStrength\n",
            "copying emoint/resources/SentiStrength/NegatingWordList.txt -> build/lib/emoint/resources/SentiStrength\n",
            "copying emoint/resources/SentiStrength/SlangLookupTable.txt -> build/lib/emoint/resources/SentiStrength\n",
            "copying emoint/resources/SentiStrength/EmotionLookupTableGeneral.txt -> build/lib/emoint/resources/SentiStrength\n",
            "copying emoint/resources/SentiStrength/IdiomLookupTable.txt -> build/lib/emoint/resources/SentiStrength\n",
            "copying emoint/resources/SentiStrength/EmoticonLookupTable.txt -> build/lib/emoint/resources/SentiStrength\n",
            "copying emoint/resources/SentiStrength/BoosterWordList.txt -> build/lib/emoint/resources/SentiStrength\n",
            "creating build/lib/emoint/resources/Sentiment140-Lexicon-v0.1\n",
            "copying emoint/resources/Sentiment140-Lexicon-v0.1/unigrams-pmilexicon.txt.gz -> build/lib/emoint/resources/Sentiment140-Lexicon-v0.1\n",
            "copying emoint/resources/Sentiment140-Lexicon-v0.1/pairs-pmilexicon.txt.gz -> build/lib/emoint/resources/Sentiment140-Lexicon-v0.1\n",
            "copying emoint/resources/Sentiment140-Lexicon-v0.1/README -> build/lib/emoint/resources/Sentiment140-Lexicon-v0.1\n",
            "copying emoint/resources/Sentiment140-Lexicon-v0.1/bigrams-pmilexicon.txt.gz -> build/lib/emoint/resources/Sentiment140-Lexicon-v0.1\n",
            "creating build/lib/emoint/resources/emoint\n",
            "copying emoint/resources/emoint/anger-ratings-0to1.dev.target.txt -> build/lib/emoint/resources/emoint\n",
            "copying emoint/resources/emoint/fear-ratings-0to1.dev.target.txt -> build/lib/emoint/resources/emoint\n",
            "copying emoint/resources/emoint/joy-ratings-0to1.train.txt -> build/lib/emoint/resources/emoint\n",
            "copying emoint/resources/emoint/anger-ratings-0to1.dev.gold.txt -> build/lib/emoint/resources/emoint\n",
            "copying emoint/resources/emoint/sadness-ratings-0to1.dev.target.txt -> build/lib/emoint/resources/emoint\n",
            "copying emoint/resources/emoint/anger-ratings-0to1.train.txt -> build/lib/emoint/resources/emoint\n",
            "copying emoint/resources/emoint/sadness-ratings-0to1.dev.gold.txt -> build/lib/emoint/resources/emoint\n",
            "copying emoint/resources/emoint/joy-ratings-0to1.dev.target.txt -> build/lib/emoint/resources/emoint\n",
            "copying emoint/resources/emoint/joy-ratings-0to1.dev.gold.txt -> build/lib/emoint/resources/emoint\n",
            "copying emoint/resources/emoint/sadness-ratings-0to1.train.txt -> build/lib/emoint/resources/emoint\n",
            "copying emoint/resources/emoint/fear-ratings-0to1.dev.gold.txt -> build/lib/emoint/resources/emoint\n",
            "copying emoint/resources/emoint/fear-ratings-0to1.train.txt -> build/lib/emoint/resources/emoint\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/emoint\n",
            "creating build/bdist.linux-x86_64/egg/emoint/tests\n",
            "copying build/lib/emoint/tests/test_ensembles.py -> build/bdist.linux-x86_64/egg/emoint/tests\n",
            "copying build/lib/emoint/tests/__init__.py -> build/bdist.linux-x86_64/egg/emoint/tests\n",
            "copying build/lib/emoint/tests/test_featurizers.py -> build/bdist.linux-x86_64/egg/emoint/tests\n",
            "creating build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/mpqa_effect_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/emoji_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/nrc_affect_intensity_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/sentiment140_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/nrc_emotion_wordlevel_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/agree_to_disagree_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/senti_wordnet_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/sentistrength.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/liwc_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/emoji_sentiment_ranking_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/bing_liu_sentiment_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/afinn_valence_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/emoint_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/nrc_hashtag_emotion_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/negating_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/__init__.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/nrc_hashtag_sentiment_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/nrc_expanded_emotion_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/base_featurizers.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/edinburgh_embeddings_featurizer.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "copying build/lib/emoint/featurizers/utils.py -> build/bdist.linux-x86_64/egg/emoint/featurizers\n",
            "creating build/bdist.linux-x86_64/egg/emoint/ensembles\n",
            "copying build/lib/emoint/ensembles/__init__.py -> build/bdist.linux-x86_64/egg/emoint/ensembles\n",
            "copying build/lib/emoint/ensembles/ensemble.py -> build/bdist.linux-x86_64/egg/emoint/ensembles\n",
            "copying build/lib/emoint/ensembles/blending.py -> build/bdist.linux-x86_64/egg/emoint/ensembles\n",
            "creating build/bdist.linux-x86_64/egg/emoint/resources\n",
            "copying build/lib/emoint/resources/w2v.twitter.edinburgh.100d.csv.gz -> build/bdist.linux-x86_64/egg/emoint/resources\n",
            "copying build/lib/emoint/resources/AFINN-en-165.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources\n",
            "copying build/lib/emoint/resources/w2v-dp-BCC-Lex.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources\n",
            "copying build/lib/emoint/resources/SentiWordNet_3.0.0.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources\n",
            "copying build/lib/emoint/resources/nrc_affect_intensity.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources\n",
            "creating build/bdist.linux-x86_64/egg/emoint/resources/Sentiment140-Lexicon-v0.1\n",
            "copying build/lib/emoint/resources/Sentiment140-Lexicon-v0.1/unigrams-pmilexicon.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources/Sentiment140-Lexicon-v0.1\n",
            "copying build/lib/emoint/resources/Sentiment140-Lexicon-v0.1/pairs-pmilexicon.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources/Sentiment140-Lexicon-v0.1\n",
            "copying build/lib/emoint/resources/Sentiment140-Lexicon-v0.1/README -> build/bdist.linux-x86_64/egg/emoint/resources/Sentiment140-Lexicon-v0.1\n",
            "copying build/lib/emoint/resources/Sentiment140-Lexicon-v0.1/bigrams-pmilexicon.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources/Sentiment140-Lexicon-v0.1\n",
            "copying build/lib/emoint/resources/emoji2vec.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources\n",
            "copying build/lib/emoint/resources/AFINN-emoticon-8.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources\n",
            "copying build/lib/emoint/resources/BingLiu.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources\n",
            "creating build/bdist.linux-x86_64/egg/emoint/resources/SentiStrength\n",
            "copying build/lib/emoint/resources/SentiStrength/EnglishWordList.txt -> build/bdist.linux-x86_64/egg/emoint/resources/SentiStrength\n",
            "copying build/lib/emoint/resources/SentiStrength/QuestionWords.txt -> build/bdist.linux-x86_64/egg/emoint/resources/SentiStrength\n",
            "copying build/lib/emoint/resources/SentiStrength/EmotionLookupTable.txt -> build/bdist.linux-x86_64/egg/emoint/resources/SentiStrength\n",
            "copying build/lib/emoint/resources/SentiStrength/NegatingWordList.txt -> build/bdist.linux-x86_64/egg/emoint/resources/SentiStrength\n",
            "copying build/lib/emoint/resources/SentiStrength/SlangLookupTable.txt -> build/bdist.linux-x86_64/egg/emoint/resources/SentiStrength\n",
            "copying build/lib/emoint/resources/SentiStrength/EmotionLookupTableGeneral.txt -> build/bdist.linux-x86_64/egg/emoint/resources/SentiStrength\n",
            "copying build/lib/emoint/resources/SentiStrength/IdiomLookupTable.txt -> build/bdist.linux-x86_64/egg/emoint/resources/SentiStrength\n",
            "copying build/lib/emoint/resources/SentiStrength/EmoticonLookupTable.txt -> build/bdist.linux-x86_64/egg/emoint/resources/SentiStrength\n",
            "copying build/lib/emoint/resources/SentiStrength/BoosterWordList.txt -> build/bdist.linux-x86_64/egg/emoint/resources/SentiStrength\n",
            "copying build/lib/emoint/resources/Emoji_Sentiment_Data_v1.0.csv -> build/bdist.linux-x86_64/egg/emoint/resources\n",
            "creating build/bdist.linux-x86_64/egg/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1\n",
            "copying build/lib/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1/unigrams-pmilexicon.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1\n",
            "copying build/lib/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1/pairs-pmilexicon.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1\n",
            "copying build/lib/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1/README -> build/bdist.linux-x86_64/egg/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1\n",
            "copying build/lib/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1/sentimenthashtags.txt -> build/bdist.linux-x86_64/egg/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1\n",
            "copying build/lib/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1/bigrams-pmilexicon.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources/NRC-Hashtag-Sentiment-Lexicon-v0.1\n",
            "creating build/bdist.linux-x86_64/egg/emoint/resources/emoint\n",
            "copying build/lib/emoint/resources/emoint/anger-ratings-0to1.dev.target.txt -> build/bdist.linux-x86_64/egg/emoint/resources/emoint\n",
            "copying build/lib/emoint/resources/emoint/fear-ratings-0to1.dev.target.txt -> build/bdist.linux-x86_64/egg/emoint/resources/emoint\n",
            "copying build/lib/emoint/resources/emoint/joy-ratings-0to1.train.txt -> build/bdist.linux-x86_64/egg/emoint/resources/emoint\n",
            "copying build/lib/emoint/resources/emoint/anger-ratings-0to1.dev.gold.txt -> build/bdist.linux-x86_64/egg/emoint/resources/emoint\n",
            "copying build/lib/emoint/resources/emoint/sadness-ratings-0to1.dev.target.txt -> build/bdist.linux-x86_64/egg/emoint/resources/emoint\n",
            "copying build/lib/emoint/resources/emoint/anger-ratings-0to1.train.txt -> build/bdist.linux-x86_64/egg/emoint/resources/emoint\n",
            "copying build/lib/emoint/resources/emoint/sadness-ratings-0to1.dev.gold.txt -> build/bdist.linux-x86_64/egg/emoint/resources/emoint\n",
            "copying build/lib/emoint/resources/emoint/joy-ratings-0to1.dev.target.txt -> build/bdist.linux-x86_64/egg/emoint/resources/emoint\n",
            "copying build/lib/emoint/resources/emoint/joy-ratings-0to1.dev.gold.txt -> build/bdist.linux-x86_64/egg/emoint/resources/emoint\n",
            "copying build/lib/emoint/resources/emoint/sadness-ratings-0to1.train.txt -> build/bdist.linux-x86_64/egg/emoint/resources/emoint\n",
            "copying build/lib/emoint/resources/emoint/fear-ratings-0to1.dev.gold.txt -> build/bdist.linux-x86_64/egg/emoint/resources/emoint\n",
            "copying build/lib/emoint/resources/emoint/fear-ratings-0to1.train.txt -> build/bdist.linux-x86_64/egg/emoint/resources/emoint\n",
            "copying build/lib/emoint/resources/NRC-Hashtag-Emotion-Lexicon-v0.2.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources\n",
            "copying build/lib/emoint/resources/NRC-emotion-lexicon-wordlevel-v0.92.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources\n",
            "copying build/lib/emoint/resources/NegatingWordList.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources\n",
            "copying build/lib/emoint/resources/LIWC2007.dic -> build/bdist.linux-x86_64/egg/emoint/resources\n",
            "copying build/lib/emoint/resources/SentiStrength.jar -> build/bdist.linux-x86_64/egg/emoint/resources\n",
            "copying build/lib/emoint/resources/mpqa.txt.gz -> build/bdist.linux-x86_64/egg/emoint/resources\n",
            "creating build/bdist.linux-x86_64/egg/emoint/utils\n",
            "copying build/lib/emoint/utils/reformat.py -> build/bdist.linux-x86_64/egg/emoint/utils\n",
            "copying build/lib/emoint/utils/__init__.py -> build/bdist.linux-x86_64/egg/emoint/utils\n",
            "copying build/lib/emoint/utils/utils.py -> build/bdist.linux-x86_64/egg/emoint/utils\n",
            "copying build/lib/emoint/__init__.py -> build/bdist.linux-x86_64/egg/emoint\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/tests/test_ensembles.py to test_ensembles.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/tests/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/tests/test_featurizers.py to test_featurizers.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/mpqa_effect_featurizer.py to mpqa_effect_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/emoji_featurizer.py to emoji_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/nrc_affect_intensity_featurizer.py to nrc_affect_intensity_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/sentiment140_featurizer.py to sentiment140_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/nrc_emotion_wordlevel_featurizer.py to nrc_emotion_wordlevel_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/agree_to_disagree_featurizer.py to agree_to_disagree_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/senti_wordnet_featurizer.py to senti_wordnet_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/sentistrength.py to sentistrength.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/liwc_featurizer.py to liwc_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/emoji_sentiment_ranking_featurizer.py to emoji_sentiment_ranking_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/bing_liu_sentiment_featurizer.py to bing_liu_sentiment_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/afinn_valence_featurizer.py to afinn_valence_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/emoint_featurizer.py to emoint_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/nrc_hashtag_emotion_featurizer.py to nrc_hashtag_emotion_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/negating_featurizer.py to negating_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/nrc_hashtag_sentiment_featurizer.py to nrc_hashtag_sentiment_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/nrc_expanded_emotion_featurizer.py to nrc_expanded_emotion_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/base_featurizers.py to base_featurizers.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/edinburgh_embeddings_featurizer.py to edinburgh_embeddings_featurizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/featurizers/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/ensembles/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/ensembles/ensemble.py to ensemble.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/ensembles/blending.py to blending.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/utils/reformat.py to reformat.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/utils/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/utils/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/emoint/__init__.py to __init__.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying EmoInt.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying EmoInt.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying EmoInt.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying EmoInt.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying EmoInt.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "emoint.featurizers.__pycache__.utils.cpython-36: module references __file__\n",
            "creating dist\n",
            "creating 'dist/EmoInt-0.1.2-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing EmoInt-0.1.2-py3.6.egg\n",
            "creating /usr/local/lib/python3.6/dist-packages/EmoInt-0.1.2-py3.6.egg\n",
            "Extracting EmoInt-0.1.2-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding EmoInt 0.1.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/EmoInt-0.1.2-py3.6.egg\n",
            "Processing dependencies for EmoInt==0.1.2\n",
            "Searching for tweetokenize==1.1.0\n",
            "Reading https://pypi.org/simple/tweetokenize/\n",
            "Couldn't find index page for 'tweetokenize' (maybe misspelled?)\n",
            "Scanning index of all packages (this may take a while)\n",
            "Reading https://pypi.org/simple/\n",
            "No local packages or working download links found for tweetokenize==1.1.0\n",
            "error: Could not find suitable distribution for Requirement.parse('tweetokenize==1.1.0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBOi-nj2nQnf",
        "colab_type": "code",
        "outputId": "5b6d050e-4f2b-45d0-cae3-772e316f03cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from emoint.featurizers.emoint_featurizer import EmoIntFeaturizer\n",
        "from tweetokenize.tweetokenize.tokenizer import Tokenizer\n",
        "%cd /content/drive/My Drive/MCA Project/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MCA Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB2S9Fn-EXQd",
        "colab_type": "code",
        "outputId": "bc69ac70-313b-46c1-f6be-d0ea12de725b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "!pip install --upgrade gensim\n",
        "!pip install libsvm\n",
        "\n",
        "# # import gensim\n",
        "# # gensim.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (1.13.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (1.16.3)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
            "Installing collected packages: gensim\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.8.3\n",
            "Collecting libsvm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/11/c7700d0cd3a21eef2d7d996256277fc640ccd4f84717c10228cb6c1567dc/libsvm-3.23.0.4.tar.gz (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 2.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: libsvm\n",
            "  Building wheel for libsvm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libsvm: filename=libsvm-3.23.0.4-cp36-cp36m-linux_x86_64.whl size=233336 sha256=01c849cf1b08df865240e41d3d9f75092b107275ea7d0f08f2470c073e702893\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/9e/b5/dbb033107407eec2f52b8cd24cf024a4b9ec8b62ea5aee995a\n",
            "Successfully built libsvm\n",
            "Installing collected packages: libsvm\n",
            "Successfully installed libsvm-3.23.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-YnmSLipTPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from gensim.models import FastText\n",
        "import re\n",
        "import numpy as np\n",
        "from libsvm import svmutil\n",
        "import libsvm\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from scipy.stats import kendalltau"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_iZ0Vt0pTS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_summary = FastText.load('project/models-4.1/model_summary.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VXcHdodrmMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data = pd.read_excel(\"Dataset/NewsHeadlines_01012019_30092019.xlsx\")\n",
        "# data.columns =[column.replace(\" \", \"_\") for column in data.columns] \n",
        "\n",
        "# ls = [1 if i < 4761 else 0 for i in range(47611)]\n",
        "# data.sort_values(\"Like_Count\", inplace=True,ascending=False)\n",
        "# data['class'] = ls\n",
        "# data[\"Category\"].replace({\"Tech\": \"Technology\",\"-\":\"Uncategorized\", \"Sports\":\"Sport\"}, inplace=True)\n",
        "# data.query(' Post_Type == \"photo\" or Post_Type == \"video\" or Post_Type == \"link\" ', inplace=True)\n",
        "# data.reset_index(inplace=True,drop=True)\n",
        "# data = data.truncate(before=0,after=4761*2)\n",
        "# data = data.sample(frac=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_0GSoHGrmP8",
        "colab_type": "code",
        "outputId": "b744384d-1b3c-4b4b-a828-e9ac71f4e12f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "data_ner = pd.read_csv(\"project/data_ner.csv\", sep=\";\")\n",
        "data_pos = pd.read_csv(\"project/data_pos.csv\")\n",
        "data_ner.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'id', 'Page', 'Date', 'Time', 'Like Count',\n",
              "       'Comment Count', 'Share Count', 'Category', 'Crime_flag', 'Feed_Img',\n",
              "       'Headline', 'Summary', 'Publish Timestamp', 'Post Message',\n",
              "       'Post Description', 'Post Link', 'Post Type', 'Post Img', 'Status Type',\n",
              "       'class', 'ner_tokens'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2IqcWnOs2DR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ner_tokens = data_ner[\"ner_tokens\"].astype(str).tolist()\n",
        "arrays = np.load(\"Final/part_d_features.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUbaz05Y2gam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check = (data_ner[data_ner['Post Type'] == 'link'])\n",
        "# print(check)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzYtw1046xea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a = data_ner[data_ner['Headline'] == 'Australian motivational speaker Nick Vujicic seen fishing in Pasir Ris']\n",
        "# b = a['ner_tokens'].tolist()\n",
        "# print(b[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raG7Zup2s2Gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # #######################################################\n",
        "\n",
        "# #headline = data[\"Headline\"].tolist()\n",
        "# headline = data_pos['Headline'].tolist()\n",
        "\n",
        "# comb_feature = []\n",
        "\n",
        "# for i in headline:\n",
        "  \n",
        "#   #pos_vec = head_vec[headline.index(i)]\n",
        "#   #print(i)\n",
        "#   if (data_ner[data_ner['Headline'] == i].empty == False):\n",
        "#     head = i\n",
        "#     ner_i = data_ner[data_ner['Headline'] == i]\n",
        "#     pos_vec = arrays[headline.index(i)]\n",
        "#     ner_token = ner_i['ner_tokens'].tolist()[0]\n",
        "#     cat = ner_i['Category'].tolist()[0]\n",
        "#     pos_type = ner_i['Post Type'].tolist()[0]\n",
        "#     class_ = ner_i[\"class\"].tolist()[0]\n",
        "#     likes = ner_i[\"Like Count\"].tolist()[0]\n",
        "\n",
        "#     comb_feature.append([head,cat,pos_type,ner_token,pos_vec,class_, likes])\n",
        "    \n",
        "\n",
        "# df = pd.DataFrame(comb_feature,columns = ['Headline','Category','Post_Type','Ner_Token','POS_Vec', 'class', \"Like Count\"])\n",
        "# df.to_csv('Combined_Features.csv')    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UJLYD72AzAi",
        "colab_type": "code",
        "outputId": "0cd91188-0fd8-489f-99a1-3ba3f1b921ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "combine_f = pd.read_csv('Combined_Features.csv')\n",
        "len(combine_f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8966"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C8WDCL5EW5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip EmoInt.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU7lR7DhEXBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### SVM for these emotions\n",
        "import re\n",
        "category = set(combine_f[\"Category\"].tolist())\n",
        "post_types = set(combine_f[\"Post_Type\"].tolist())\n",
        "ner = combine_f[\"Ner_Token\"].astype(str).tolist()\n",
        "# ner = [re.sub(\"\\\"'\\]\\[(),\",\"\", n) for n in ner] \n",
        "# print(ner)\n",
        "headlines= []\n",
        "for sent_str in combine_f[\"Headline\"]:\n",
        "#     sent_str = re.sub(r\"'\", \"\", str(sent_str).lower())\n",
        "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", str(sent_str).lower()).split()\n",
        "    if(tokens == []):\n",
        "        tokens = \"nan\"\n",
        "    headlines.append(tokens)\n",
        "    \n",
        "cat_vec = {}\n",
        "for c in category:\n",
        "    cat_vec[c] = model_summary.wv[c] \n",
        "\n",
        "for c in post_types:\n",
        "    cat_vec[c] = model_summary.wv[c]\n",
        "    \n",
        "head_vec = []\n",
        "n = len(headlines)\n",
        "for h in range(n):\n",
        "    sum1 = np.array([0.0 for i in range(100)])\n",
        "    for tok in ner[h]:\n",
        "        sum1+=model_summary.wv[tok[0]]\n",
        "#     print(sum1)\n",
        "    sum1 = sum1/len(headlines[h])\n",
        "#     print(sum1)\n",
        "    sum1 = np.concatenate((sum1,cat_vec[combine_f[\"Category\"][h]],cat_vec[combine_f[\"Post_Type\"][h]], arrays[h]))\n",
        "    head_vec.append(sum1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f4GJQgoEW_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "head_vec = np.array(head_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6rOmmtXp9gg",
        "colab_type": "code",
        "outputId": "450b52a5-b2ec-46af-909a-f2e5351059e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "feat_len = int(0.8*len(head_vec))\n",
        "train = head_vec[:feat_len]\n",
        "res_train = list(np.log2(np.array(combine_f[\"Like Count\"][:feat_len].tolist())+1))\n",
        "test = head_vec[feat_len:]\n",
        "res_test = list(np.log2(np.array(combine_f[\"Like Count\"][feat_len:].tolist())+1))\n",
        "print(len(train), len(res_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7172 7172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "343Pf8h6yYEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_svm = svmutil.svm_train(res_train, train,'-s 4 -t 2 -c 2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdvoFK2ez1Uh",
        "colab_type": "code",
        "outputId": "b08a597c-adfa-482a-a8ef-3d6c7a5a19ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_reg = svmutil.svm_predict(res_test, test, model_svm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error = 0.852503 (regression)\n",
            "Squared correlation coefficient = 0.0155141 (regression)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W5_yfsiz58O",
        "colab_type": "code",
        "outputId": "afe3f847-34f3-4bf3-b1b7-446388636545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "r2 = r2_score(res_test,y_reg[0])\n",
        "r2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0069312434031263415"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb7GfYI7z8Ud",
        "colab_type": "code",
        "outputId": "9c81c835-59e5-435b-d02b-a7e44d8d71a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mae = mean_absolute_error(res_test, y_reg[0])\n",
        "mae"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7070243139174582"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwKEQshK4LOk",
        "colab_type": "code",
        "outputId": "1e42c896-4639-4728-ef15-dc819ea154ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "kt = kendalltau(res_test, y_reg[0])\n",
        "kt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KendalltauResult(correlation=0.05061933952664544, pvalue=0.0013254708237548322)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyOh7BjP4N6S",
        "colab_type": "code",
        "outputId": "8a2abc85-3f56-4953-a7b3-6d13655806b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_full = svmutil.svm_predict(res_test+res_train, list(test)+list(train), model_svm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error = 0.852925 (regression)\n",
            "Squared correlation coefficient = 0.041989 (regression)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy1pPsqk4QaO",
        "colab_type": "code",
        "outputId": "d691f3b8-bd4e-431b-d416-534aaf300538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "r2 = r2_score(res_test+res_train,y_full[0])\n",
        "r2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03010300711181313"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a6bD4Hl4TA_",
        "colab_type": "code",
        "outputId": "93d2760d-b4c5-4e41-f0fb-b6aabd86fb76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mae = mean_absolute_error(res_test+res_train, y_full[0])\n",
        "mae"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7099582542934694"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BNjOjwxDGID",
        "colab_type": "code",
        "outputId": "aaadeb0d-ee92-464c-8547-b5d857f0f60d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "kt = kendalltau(res_test+res_train, y_full[0])\n",
        "kt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KendalltauResult(correlation=0.114347213706982, pvalue=3.31886386289321e-59)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUe9gxN0DMho",
        "colab_type": "code",
        "outputId": "1d7fa983-29ce-468e-86c2-692512611b18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_tr = svmutil.svm_predict(res_train, train, model_svm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error = 0.85303 (regression)\n",
            "Squared correlation coefficient = 0.0507558 (regression)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABrutTlADQYn",
        "colab_type": "code",
        "outputId": "71f48711-797b-4b17-dcc1-2701bdefa16e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "r2 = r2_score(res_train,y_tr[0])\n",
        "r2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03559201623233754"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6wDiIjMDR4k",
        "colab_type": "code",
        "outputId": "e9543782-f7f6-49b4-f2c7-b8379fae9075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mae = mean_absolute_error(res_train, y_tr[0])\n",
        "mae"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7106921484700678"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvnlZufjDSJO",
        "colab_type": "code",
        "outputId": "8d504b90-afaa-4ed8-d574-95158cfb81f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "kt = kendalltau(res_train, y_tr[0])\n",
        "kt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KendalltauResult(correlation=0.1304098739530009, pvalue=1.6101251256833384e-61)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FV_onqP4V0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svmutil.svm_save_model(\"model_all4_regression.bin\",model_svm)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxbmC3Gn4a1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_svm_reg = svmutil.svm_train(res_train+res_test, list(train)+list(test),'-s 4 -v 10 -t 2 -c 2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1wJp_lz4fGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#With EmoInt-------------------------------------------------------------------------------------------------------------\n",
        "featurizer = EmoIntFeaturizer()\n",
        "tokenizer = Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSUe-1tq5HdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vector(h):\n",
        "    \n",
        "    headlines = []\n",
        "    i= 0\n",
        "    for sent_str in h:\n",
        "\n",
        "        # print(i)\n",
        "\n",
        "        i+=1\n",
        "\n",
        "        features = featurizer.featurize(str(sent_str), tokenizer)\n",
        "        \n",
        "        headlines.append(features)\n",
        "    \n",
        "    return headlines\n",
        "head_vec2 = get_vector(headlines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fXCuNt08C3s",
        "colab_type": "code",
        "outputId": "753f9f52-da88-48dc-aa18-be0f41e7bb1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "hv = []\n",
        "\n",
        "for i, h in enumerate(list(head_vec)):\n",
        "  # print(head_vec2[i])\n",
        "  hv.append(list(h)+ head_vec2[i])\n",
        "hv = np.array(hv)\n",
        "hv.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8966, 439)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuGDw_p-5mEp",
        "colab_type": "code",
        "outputId": "68efc86c-1db3-4f24-c7cd-ff9e28b615c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "feat_len = int(0.8*len(head_vec))\n",
        "train = hv[:feat_len]\n",
        "res_train = list(np.log2(np.array(combine_f[\"Like Count\"][:feat_len].tolist())+1))\n",
        "test = hv[feat_len:]\n",
        "res_test = list(np.log2(np.array(combine_f[\"Like Count\"][feat_len:].tolist())+1))\n",
        "print(len(train), len(res_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7172 7172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoLIECOJ9l3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_svm = svmutil.svm_train(res_train, train,'-s 4 -t 2 -c 2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SucNKFY9pXK",
        "colab_type": "code",
        "outputId": "950de3e8-d097-4128-bb82-6475702f3340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_reg = svmutil.svm_predict(res_test, test, model_svm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error = 0.85496 (regression)\n",
            "Squared correlation coefficient = 0.0232747 (regression)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLR_lBpG-cO7",
        "colab_type": "code",
        "outputId": "d973727c-22c5-41d9-899a-a1cd52ed6926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "r2 = r2_score(res_test,y_reg[0])\n",
        "r2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.004069288767440615"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRWoCGhyEHJs",
        "colab_type": "code",
        "outputId": "20c1ef10-831d-4bb7-cc58-be0a0c8e2c79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mae = mean_absolute_error(res_test, y_reg[0])\n",
        "mae"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7151406467778908"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8NsxVJPEJgc",
        "colab_type": "code",
        "outputId": "bb626b37-75a8-4582-9a7b-1fdb3875a85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "kt = kendalltau(res_test, y_reg[0])\n",
        "kt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KendalltauResult(correlation=0.10525713081920006, pvalue=2.4609379418145102e-11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE4oQFvUEMDJ",
        "colab_type": "code",
        "outputId": "853a8186-4a7a-457f-d021-8a08fa2eebe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_full = svmutil.svm_predict(res_test+res_train, list(test)+list(train), model_svm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error = 0.21557 (regression)\n",
            "Squared correlation coefficient = 0.760893 (regression)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMW44R6KEOqO",
        "colab_type": "code",
        "outputId": "f82e549b-8dff-4cf5-bced-4183f2202ef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "r2 = r2_score(res_test+res_train,y_full[0])\n",
        "r2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7548667812860071"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npt0zVPoEuTD",
        "colab_type": "code",
        "outputId": "e54024f6-3ed2-439f-adac-ed70dbbeb894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mae = mean_absolute_error(res_test+res_train, y_full[0])\n",
        "mae"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18201188277888863"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt4wyqPNExdD",
        "colab_type": "code",
        "outputId": "1a49ccf1-44b8-4ea0-84c7-33c2b5612368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "kt = kendalltau(res_test+res_train, y_full[0])\n",
        "kt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KendalltauResult(correlation=0.7924746551582417, pvalue=0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjtdxz-HE0Ca",
        "colab_type": "code",
        "outputId": "123a9bb8-cd25-4a7b-cd66-c3e7440eea3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_tr = svmutil.svm_predict(res_train, train, model_svm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error = 0.0556327 (regression)\n",
            "Squared correlation coefficient = 0.946801 (regression)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1vuC54bE2p1",
        "colab_type": "code",
        "outputId": "5314777a-fe46-42c9-8953-55ec4f5f6560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "r2 = r2_score(res_train,y_tr[0])\n",
        "r2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9371034975675214"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNpNBZCHE8io",
        "colab_type": "code",
        "outputId": "9a8823b3-26f7-4491-cf5d-18ea55ddad8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mae = mean_absolute_error(res_train, y_tr[0])\n",
        "mae"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.048655357037922384"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDVR3Un7FIwQ",
        "colab_type": "code",
        "outputId": "48c54853-80b2-4387-8387-f96c82b45e96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "kt = kendalltau(res_train, y_tr[0])\n",
        "kt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KendalltauResult(correlation=0.9829589100789742, pvalue=0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C684iniFLgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svmutil.svm_save_model(\"model_all5_regression.bin\",model_svm)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vSn5ixMFRJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}